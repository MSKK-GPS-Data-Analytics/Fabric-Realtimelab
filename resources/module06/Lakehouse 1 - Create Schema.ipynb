{"cells":[{"cell_type":"markdown","source":["## Lakehouse l - Create Schema\n","This run-once notebook will setup the schema for building the lakehouse.\n","Configure the sourceTableName variable in the first cell (if needed) to match the table where stock events are being ingested. The begin/end dates are for the date dimension table."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"071a8446-0a66-4beb-a194-d72157f16aa6"},{"cell_type":"code","source":["# configure the source table name (if needed) and begin/end dates for the date dimension\n","\n","from delta.tables import *\n","from pyspark.sql.functions import *\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import concat, col, lit, when, substring, monotonically_increasing_id \n","from datetime import datetime\n","\n","# name of source table from eventstream\n","sourceTableName = 'raw_stock_data'\n","\n","# begin/end dates for dim_date table\n","beginYear = 2023\n","endYear = datetime.today().year + 2\n","\n","if not spark.catalog.tableExists(sourceTableName):\n","    msg = f'Warning! Source table not found: {sourceTableName}'\n","    print(msg)"],"outputs":[],"execution_count":null,"metadata":{},"id":"9bd16c06-c5b9-41f8-92f2-e482401886ba"},{"cell_type":"code","source":["# main fact table for stock data\n","\n","def create_fact_Stocks_Daily_Prices():\n","    spark.sql(f\"\"\"\n","        CREATE OR REPLACE TABLE fact_Stocks_Daily_Prices (\n","            Symbol_SK LONG NOT NULL\n","            ,PriceDateKey DATE \n","            ,MinPrice DOUBLE \n","            ,MaxPrice DOUBLE \n","            ,ClosePrice DOUBLE)\n","        USING DELTA\n","        \"\"\")\n","    \n","create_fact_Stocks_Daily_Prices()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"112a629f-33dd-4f02-bb5c-5d4828e0c5d9"},{"cell_type":"code","source":["# symbol dimension holds details about each company\n","\n","def create_dim_symbol():\n","    spark.sql(f\"\"\"\n","        CREATE OR REPLACE TABLE dim_symbol (\n","            Symbol_SK LONG NOT NULL\n","            ,Symbol VARCHAR(5) NOT NULL\n","            ,Name VARCHAR(25)\n","            ,Market VARCHAR(15) )\n","        USING DELTA\n","        \"\"\")\n","\n","create_dim_symbol()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"00869ec8-98cf-4fbf-9972-bbc30eb6aee3"},{"cell_type":"code","source":["# load the symbol table by getting a list of distinct symbols from source table\n","\n","def dim_symbol_initial_load(sourceTableName):\n","\n","    if not spark.catalog.tableExists(sourceTableName):\n","        msg = f'Warning! Source table not found: {sourceTableName}. Will not load stock symbols.'\n","        print(msg)\n","        return\n","\n","    # get unique stock symbols in source table\n","    df_stocks = spark.sql(f\"SELECT distinct(symbol), DENSE_RANK() OVER(ORDER BY symbol asc) row FROM {sourceTableName}\")\n","\n","    df_symbols = df_stocks.select(\"Symbol\", \"row\")\n","    df_symbols = df_symbols.withColumn(\"Symbol_SK\", col(\"row\"))\n","    df_symbols = df_symbols.withColumn(\"Name\", when(df_symbols.Symbol == \"BCUZ\",\"Company Because\") \\\n","        .when(df_symbols.Symbol == \"IDGD\",\"Company IDontGiveADarn\") \\\n","        .when(df_symbols.Symbol == \"IDK\",\"Company IDontKnow\") \\\n","        .when(df_symbols.Symbol == \"TDY\",\"Company Today\") \\\n","        .when(df_symbols.Symbol == \"TMRW\",\"Company Tomorrow\") \\\n","        .when(df_symbols.Symbol == \"WHAT\",\"Company What\") \\\n","        .when(df_symbols.Symbol == \"WHY\",\"Company Why\") \\\n","        .when(df_symbols.Symbol == \"WHO\",\"Company Who\") \\\n","        .otherwise(\"Company Unknown\"))\n","    df_symbols = df_symbols.withColumn(\"Market\", when(substring(df_symbols.Symbol,1,1) == \"B\",\"NASDAQ\") \\\n","                            .when(substring(df_symbols.Symbol,1,1) == \"W\",\"NASDAQ\") \\\n","                            .when(substring(df_symbols.Symbol,1,1) == \"I\",\"NYSE\") \\\n","                            .when(substring(df_symbols.Symbol,1,1) == \"T\",\"NYSE\") \\\n","                            .otherwise(\"No Market\"))\n","\n","    # merge the symbols into the table\n","    dim_symbol_table = DeltaTable.forName(spark, \"dim_symbol\")\n","\n","    dim_symbol_table.alias('dim_symbol') \\\n","    .merge( \\\n","        df_symbols.alias('updates'), \\\n","        'dim_symbol.Symbol = updates.Symbol' \\\n","    ) \\\n","    .whenNotMatchedInsert(values = \\\n","        { \n","            \"Symbol_SK\": \"updates.Symbol_SK\"\n","            ,\"Symbol\": \"updates.Symbol\"\n","            ,\"Name\": \"updates.Name\"\n","            ,\"Market\": \"updates.Market\"\n","        } \\\n","    ) \\\n","    .execute()\n","\n","    df_dimSymbol = spark.sql(\"SELECT * FROM dim_symbol\")\n","    df_dimSymbol.show()\n","\n","dim_symbol_initial_load(sourceTableName)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"e6ce3035-2a2d-448e-adcf-7de1696ee50e"},{"cell_type":"code","source":["# create and populate our metadata table that tracks the last run \n","\n","def createAndPopulate_etlIngestSourceInfo(tableName='raw_stock_data', waterMark='2022-12-31 23:59:59.00000', isActive='Y'):\n","    spark.sql(f\"\"\"\n","        CREATE OR REPLACE TABLE etl_IngestSourceInfo (\n","            ObjectName VARCHAR(50) NOT NULL\n","            ,WaterMark VARCHAR(50) NOT NULL\n","            ,IsActiveFlag VARCHAR(1) )\n","        USING DELTA\n","        \"\"\")\n","\n","    spark.sql(f\"INSERT INTO etl_IngestSourceInfo SELECT '{tableName}', '{waterMark}', '{isActive}'\")\n","    etl_df = spark.sql(f\"SELECT * FROM etl_IngestSourceInfo\")\n","    etl_df.show()\n","\n","createAndPopulate_etlIngestSourceInfo(sourceTableName, \"2022-12-31 23:59:59.00000\", \"Y\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a69f25df-22e6-4ba2-8cff-683eb236ea0f"},{"cell_type":"code","source":["# create and populate the date dimension\n","\n","def createAndPopulate_dim_date(beginYear=2022, endYear=2025):\n","\n","    # Create a DataFrame with a range of dates\n","    dates = spark.range(\n","        (datetime(endYear, 12, 31) - datetime(beginYear, 1, 1)).days + 1\n","    ).select(\n","        (date_add(lit(f\"{beginYear}-01-01\"), col(\"id\").cast(\"int\"))).alias(\"date\")\n","    )\n","\n","    # Select the desired columns\n","    datesdf = dates.select(\n","        date_format(\"date\",\"yyyy-MM-dd\").cast('date').alias(\"DateKey\"),\n","        dayofmonth(\"date\").alias(\"DayNum\"),\n","        dayofweek(\"date\").alias(\"DayOfWeekNum\"),\n","        date_format(\"date\", \"EEEE\").alias(\"DayOfWeekName\"),\n","        month(\"date\").alias(\"MonthNum\"),\n","        date_format(\"date\", \"MMMM\").alias(\"MonthName\"),\n","        quarter(\"date\").alias(\"QuarterNum\"),\n","        concat(lit(\"Q\"), quarter(\"date\")).alias(\"QuarterName\"),\n","        year(\"date\").alias(\"Year\")\n","    )\n","\n","    datesdf.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"dim_date\")\n","    datesdf.show()\n","\n","createAndPopulate_dim_date(beginYear, endYear)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"849af595-b53e-44a3-b15d-ef77c1cec60d"},{"cell_type":"code","source":["# drop tables for testing\n","\n","def dropTables():\n","    spark.sql(\"DROP TABLE fact_stocks_daily_prices\")\n","    spark.sql(\"DROP TABLE dim_symbol\")\n","    spark.sql(\"DROP TABLE dim_date\")\n","    spark.sql(\"DROP TABLE etl_ingestsourceinfo\")\n","\n","# dropTables()"],"outputs":[],"execution_count":null,"metadata":{"editable":true,"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"run_control":{"frozen":false}},"id":"0bddc9fc-3946-4b63-a189-075836e6b31e"},{"cell_type":"code","source":["# optional optimization, recommended for small tables\n","# typically scheduled for regular maintenance\n","\n","def optimizeTables(sourceTableName):\n","\n","    dim_date_table = DeltaTable.forName(spark, \"dim_date\")\n","    dim_date_table.optimize().executeCompaction()\n","\n","    dim_symbol_table = DeltaTable.forName(spark, \"dim_symbol\")\n","    dim_symbol_table.optimize().executeCompaction()\n","\n","    etl_ingestsourceinfo_table = DeltaTable.forName(spark, \"etl_ingestsourceinfo\")\n","    etl_ingestsourceinfo_table.optimize().executeCompaction()\n","\n","    fact_stock_prices_table = DeltaTable.forName(spark, \"fact_stocks_daily_prices\")\n","    fact_stock_prices_table.optimize().executeCompaction()\n","\n","    if spark.catalog.tableExists(sourceTableName):\n","        StockData_table = DeltaTable.forName(spark, sourceTableName)\n","        StockData_table.optimize().executeCompaction()\n","\n","optimizeTables(sourceTableName)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"55f55603-639f-4e2b-abe9-cc6633eff1f9"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python"},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"state":{},"version":"0.1"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"trident":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}